{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import deque\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_img(img):\n",
    "    img = (img / 127.5) - 1\n",
    "    return img\n",
    "def load_images(data_dir, batch_size):\n",
    "    image_shape = (32, 32, 3)\n",
    "    sample_dim = (batch_size,) + image_shape\n",
    "    sample = np.empty(sample_dim, dtype=np.float32)\n",
    "    \n",
    "    sample_imgs_paths = [join(data_dir, f) for f in listdir(data_dir) if 'png' in f]\n",
    "    for index,img_filename in enumerate(sample_imgs_paths):\n",
    "        image = Image.open(img_filename)\n",
    "        image = image.resize(image_shape[:-1])\n",
    "        image = image.convert('RGB')\n",
    "        image = np.asarray(image)\n",
    "#         image = norm_img(image)\n",
    "        sample[index,...] = image\n",
    "    return sample\n",
    "\n",
    "def preocess_imge(images):\n",
    "    images.reshape(images.shape[0], 32, 32, 3).astype('int8')\n",
    "    images /= 255.\n",
    "    images[images  >= .5] = 1.\n",
    "    images[images < .5] = 0.\n",
    "    return images\n",
    "def get_batch_image(images, batch_size, IMAGE_SHAPE):\n",
    "    np.random.shuffle(images)\n",
    "    return [images[i*batch_size : (i+1) *batch_size] for i in range(images.shape[0] // batch_size)]\n",
    "\n",
    "IMAGE_SHAPE = (32, 32, 3)\n",
    "data_dir = './input_source_word/'\n",
    "BATCH_SIZE = 100\n",
    "train_images = preocess_imge(load_images(data_dir, BATCH_SIZE))\n",
    "test_images = preocess_imge(load_images(data_dir, BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0])\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[32, 32, 3]))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2D(256, (2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "def discriminator_loss(real_output, fake_output, gen_output):\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    gen_loss = cross_entropy(tf.zeros_like(gen_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss + gen_loss\n",
    "    return total_loss\n",
    "def generator_loss(fake_output):\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_encoder(latent_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=(32, 32, 3)))\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(latent_dim + latent_dim))\n",
    "    return model\n",
    "\n",
    "def make_decoder(latent_dim):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(8*8*32, use_bias=False, input_shape=(latent_dim,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((8, 8, 32)))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'))\n",
    "    model.add(layers.Conv2DTranspose(filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'))\n",
    "    model.add(layers.Conv2DTranspose(filters=3, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation='relu'))\n",
    "    return model\n",
    "\n",
    "@tf.function\n",
    "def sample(decoder, test_input, eps=None):\n",
    "    latent_dim = 50\n",
    "    if eps is None:\n",
    "        eps = tf.random.normal(shape=(100, latent_dim))\n",
    "    return decode(decoder, test_input, apply_sigmoid=True)\n",
    "\n",
    "def encode(encoder, x):\n",
    "    mean, logvar = tf.split(encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "def reparameterize(mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "def decode(decoder, z, apply_sigmoid=False):\n",
    "    logits = decoder(z)\n",
    "    if apply_sigmoid:\n",
    "        probs = tf.sigmoid(logits)\n",
    "        return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "num_examples_to_generate = 1\n",
    "\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "encoder = make_encoder(latent_dim)\n",
    "encoder_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "decoder = make_decoder(latent_dim)\n",
    "decoder_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(random_vector_for_generation.shape)\n",
    "decoder.summary()\n",
    "# sample(decoder, latent_dim)\n",
    "# decoder(random_vector_for_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "          -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "          axis=raxis)\n",
    "\n",
    "@tf.function\n",
    "def gen_from_vae(encoder, decoder, x):\n",
    "    mean, logvar = encode(encoder, x)\n",
    "    z = reparameterize(mean, logvar)\n",
    "    x_gen = decode(decoder, z)\n",
    "    return x_gen, mean, logvar, z\n",
    "\n",
    "@tf.function\n",
    "def get_recon_loss(recon, source):\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=recon, labels=source)\n",
    "    return tf.reduce_mean(tf.reduce_sum(cross_ent, axis=[1, 2, 3]))\n",
    "\n",
    "@tf.function\n",
    "def get_encode_loss(recon, source, mean, logvar, z):\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=recon, labels=source)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def kl_loss(encoder, decoder, x):\n",
    "    mean, logvar = encode(encoder, x)\n",
    "    z = reparameterize(mean, logvar)\n",
    "    x_logit = decode(decoder, z)\n",
    "\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(source_images, noise_dim, batch_size):\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as encoder_tape, tf.GradientTape() as decoder_tape, tf.GradientTape() as disc_tape:\n",
    "        recon_images, mean, logvar, z = gen_from_vae(encoder, decoder, source_images)\n",
    "        generated_images = decode(decoder, noise)\n",
    "\n",
    "        real_output = discriminator(source_images, training=True)\n",
    "        gen_output = discriminator(recon_images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        encode_loss = get_encode_loss(recon_images, source_images, mean, logvar, z)\n",
    "        decode_loss = get_recon_loss(recon_images, source_images) + \\\n",
    "                        generator_loss(gen_output) + generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output, gen_output)\n",
    "\n",
    "    gradients_of_encoder = encoder_tape.gradient(encode_loss, encoder.trainable_variables)\n",
    "    gradients_of_decoder = decoder_tape.gradient(decode_loss, decoder.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    encoder_optimizer.apply_gradients(zip(gradients_of_encoder, encoder.trainable_variables))\n",
    "    decoder_optimizer.apply_gradients(zip(gradients_of_decoder, decoder.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(output_dir, epoch, test_input):\n",
    "    predictions = sample(decoder, test_input)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(1):\n",
    "        plt.subplot(1, 1, i+1)\n",
    "        plt.imshow(predictions[i, :, :, :])\n",
    "        plt.axis('off')\n",
    "\n",
    "    # tight_layout minimizes the overlap between 2 sub-plots\n",
    "    plt.savefig('{}image_at_epoch_{:04d}.png'.format(output_dir, epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 10\n",
    "begin = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_and_save_images(output_dir, 0, random_vector_for_generation)\n",
    "\n",
    "for epoch in range(begin, epochs + begin):\n",
    "    start_time = time.time()\n",
    "    image_batches = get_batch_image(train_images, batch_size, IMAGE_SHAPE)\n",
    "    for train_x in image_batches:\n",
    "        train_step(train_x, latent_dim, batch_size)\n",
    "    end_time = time.time()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        loss = tf.keras.metrics.Mean()\n",
    "        loss(kl_loss(encoder, decoder, test_images))\n",
    "        elbo = loss.result()\n",
    "        display.clear_output(wait=False)\n",
    "        print('Epoch: {}, Test set ELBO: {}, '\n",
    "              'time elapse for current epoch {}'.format(epoch,\n",
    "                                                        elbo,\n",
    "                                                        end_time - start_time))\n",
    "        generate_and_save_images(\n",
    "            output_dir, epoch, random_vector_for_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(random_vector_for_generation.shape)\n",
    "predictions = sample(decoder, random_vector_for_generation)\n",
    "print(predictions.shape)\n",
    "print(len(train_images))\n",
    "plt.imshow(predictions[0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in train_images:\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def to_grey(rgb):\n",
    "     return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "plt.figure(figsize=(8,40))\n",
    "for i, input_img in enumerate(train_images[30:]):\n",
    "    k = 20\n",
    "    x = train_images[i:i+1]\n",
    "    mean, logvar = encode(encoder, x)\n",
    "    z = reparameterize(mean, logvar)\n",
    "    gen_imge = decode(decoder, z)\n",
    "    plt.title(str(i))\n",
    "    plt.subplot(k+1, 2, 2*i+1)\n",
    "    plt.imshow(x[0,:,:,:])\n",
    "    plt.subplot(k+1, 2, 2*i+2)\n",
    "    plt.imshow(to_grey(gen_imge[0,:,:,:]), cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "    if i == k:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_diff_vector(x, y):\n",
    "    mean, logvar = encode(encoder, x)\n",
    "    z1 = reparameterize(mean, logvar)\n",
    "    \n",
    "    mean, logvar = encode(encoder, y)\n",
    "    z2 = reparameterize(mean, logvar)\n",
    "    return z2- z1\n",
    "\n",
    "def change_from(source, target, step):\n",
    "    output_dir = './moving_output/'\n",
    "    mean, logvar = encode(encoder, source)\n",
    "    z = reparameterize(mean, logvar)\n",
    "    \n",
    "    w = get_diff_vector(source, target)\n",
    "    \n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    for i in range(2 * step):\n",
    "        if i < step:\n",
    "            z += (1.0 / step) * w\n",
    "        else:\n",
    "            z -= (1.0 / step) * w\n",
    "        gen_imge = decode(decoder, z)\n",
    "        plt.imshow(to_grey(gen_imge[0,:,:,:]), cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "        plt.savefig('{}image_at_epoch_{}.png'.format(output_dir, str(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "source, target = train_images[17:18], train_images[30:31]\n",
    "change_from(source, target, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "anim_file = 'cvae_girl_heart.gif'\n",
    "output_dir = './moving_output/'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('{}*.png'.format(output_dir))\n",
    "    filenames = sorted(filenames, key = lambda x : int(x.replace('.png', '').split('_')[-1]))\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "if IPython.version_info >= (6,2,0,''):\n",
    "    display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save('./model/encoder50_test.h5') \n",
    "discriminator.save('./model/discriminator50_test.h5') \n",
    "decoder.save('./model/decoder50_test.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
